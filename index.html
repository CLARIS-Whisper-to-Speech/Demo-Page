<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="theme-color" content="#712cf9">
    <title>CLARIS: Clear and Intelligible Speech from Whispered and Dysarthric Voices</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-GLhlTQ8iRABdZLl6O3oVMWSktQOp6b7In1Zl3/Jr59b6EGGoI1aFkw7cmDA6j6gD" crossorigin="anonymous">
    <link rel="stylesheet" href="styles.css">

    <style>
        body {
            background-color: #f8f9fa;
        }

        .title-section {
            background-color: #712cf9;
            color: white;
            padding: 40px;
            margin: 32px;
            border-radius: 32px;
        }

        .author-section {
            margin-top: 30px;
            margin-bottom: 30px;
        }

        .author-info p {
            font-size: 1.1rem;
            margin-bottom: 0;
        }

        .accepted-section {
            margin: 40px 0;
        }

        .btn-primary {
            font-size: 1.2rem;
            padding: 10px 20px;
        }
    </style>
</head>

<body>
    <script src='scripts.js'></script>
    <div class="container-fluid" style="padding: 16px">
        <!-- Title Section -->
        <div class="row title-section text-center">
            <div class="col">
                <h1 class="display-4">
                    CLARIS: Clear and Intelligible Speech from Whispered and Dysarthric Voices
                </h1>
            </div>
        </div>

        <!-- Author Section -->
        <div class="row justify-content-center author-section">
            <div class="col-lg-8 text-center author-info">
                <p class="lead">
                   Authors: Anonymous
                </p>
            </div>
        </div>  

        <!-- Keynote Presentation Section -->
        <div class="row resources-section">
            <!-- <div class="col text-center" style="width: 150px">
                <p>
                    <a href="https://drive.google.com/file/d/1zMZ8qohblECAI2UF-M9jSm6uvzkZe8EV/view?usp=sharing" target="_blank" class="btn btn-primary" style="font-size: 1.2rem;">
                        View Keynote Presentation
                    </a>
                </p>
            </div>
            <div class="col text-center" style="width: 150px">
                <p>
                    <a href="https://drive.google.com/drive/folders/1PqjpBvluLSYzQQN9mDY8fMXCrfYHHua2?usp=drive_link" target="_blank" class="btn btn-primary" style="font-size: 1.2rem;">
                        Download StethoText dataset
                    </a>
                </p>
            </div> -->
            <div class="col text-center" style="width: 150px">
                <p>
                    <a href="https://github.com/CLARIS-Whisper-to-Speech/Demo-Page" target="_blank" class="btn btn-primary" style="font-size: 1.2rem;">
                        View Official Code
                    </a>
                </p>
            </div>
        </div>

        <!-- Video Section -->
        <!-- <div class="row video-section">
            <div class="col-12 text-center">
                <iframe width="560" height="315" src="" 
                    title="YouTube video player" 
                    frameborder="0" 
                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                    allowfullscreen></iframe>
            </div>
        </div> -->
        
        <div class="row p-2">

        </div>
        <div class="row">
            <h3>Abstract: </h4>
        </div>
        <div class="row p-1">

        </div>
        <div class="row">
            <p class="fs-5">
                Whispered and disordered speech, such as dysarthria, often lack intelligibility, making voice interaction difficult in both everyday and
                clinical contexts. We present CLARIS a lightweight autoregressive system that converts atypical input into natural-sounding speech.
                Unlike prior approaches that rely on paired data or handcrafted pseudo-whispers, CLARIS combines a TTS-based augmentation
                pipeline, adversarial alignment between synthetic and real speech, and multi-task linguistic supervision. Across benchmarks, it
                achieves 12.04 % WER on unseen English whisper speakers, adapts to new accents with only 30 minutes of calibration, and restores
                intelligibility for dysarthric voices where existing models fail. We further show generalization to a language linguistically distant from
                English with only 7 hours of data. Listener studies confirm gains in naturalness, prosody, and perceived normalness. By enabling
                lightweight personalization, CLARIS points toward inclusive, private, and socially mindful voice technologies for diverse users.
            </p>
        </div>

        <div class="row p-2"></div>
        
        <div class="row">
            <h3> CLARIS Teaser Diagram</h4>
        </div>
        <div class="row p-2"></div>
        <div class="row">
            <figure class="figure text-center" style="max-width: 90%; margin: 0 auto;">
                <img src="resources/images/Teaser_2Spk_New.png" alt="..." class="figure-img" style="max-width: 100%; height: auto; display: block; margin: 0 auto;">
                <figcaption class="figure-caption text-center">
                    CLARIS restores intelligibility for atypical voices across languages and disorders. (A) For whispered Hindi speech, where
                    formant energies are absent in the spectrogram, CLARIS reconstructs the missing cues so that listeners hear natural, intelligible speech
                    through a mobile API. (B) For high-severity dysarthria, where articulation is severely degraded and words are nearly unintelligible,
                    the same pipeline produces speech that can be followed in everyday communication. Together, these scenarios illustrate how CLARIS
                    supports accessible and inclusive conversations across diverse speaking conditions.
                </figcaption>
            </figure>
        </div>

        <div class="row p-3"></div>
        
        <div class="row">
            <h3> Proposed Method</h4>
        </div>
        <div class="row p-2"></div>
        <div class="row">
            <figure class="figure text-center" style="max-width: 90%; margin: 0 auto;">
                <img src="resources/images/Model_Overview.png" alt="..." class="figure-img" style="max-width: 100%; height: auto; display: block; margin: 0 auto;">
                <figcaption class="figure-caption text-center">
                    High-level overview of the CLARIS speech restoration framework. Whisper or dysarthria-like atypical speech inputs are
                    collected from the user. During training, limited paired audio–text data is expanded through a TTS-based augmentation pipeline to
                    generate synthetic inputs. Both real and synthetic audio are encoded by the AS2UT encoder; embeddings are supervised by character
                    decoders and aligned by the Real–Synthetic Alignment Discriminator (RSAD) via a gradient reversal layer (GRL). The unit prediction
                    decoder then generates speech units, aided by a CTC decoder, which are converted into natural speech by the unit-to-speech renderer.
                    The red dotted path illustrates inference: user audio is passed through the encoder, decoder, and renderer to restore intelligible speech.
                </figcaption>
            </figure>
        </div>
    </div>

    <div class="d-block p-3 experimentSection">
        <h3 class="sectionTitle">R1: CLARIS outperforms all baselines on the wTIMIT corpus</h3>
        <div class="row d-flex table-responsive overflow-auto audioContainer" id="wTIMIT44Container"></div>
        <div class="row d-flex table-responsive overflow-auto audioContainer" id="wTIMIT4UnseenContainer"></div>
    </div>
    <div class="d-block p-3 experimentSection">
        <h3 class="sectionTitle">R2: Zero-Shot and One-Shot methods fail on unseen accents. CLARIS presents a way to recover performance through personlization using only 15-30mins of data</h3>
        <div class="row d-flex table-responsive overflow-auto audioContainer" id="IndianAccentEnglishContainer"></div>
    </div>
    <div class="d-block p-3 experimentSection">
        <h3 class="sectionTitle">R3: Our Approach works for new languages as well</h3>
        <div class="row d-flex table-responsive overflow-auto audioContainer" id="HindiContainer"></div>
    </div>
    <div class="d-block p-3 experimentSection">
        <h3 class="sectionTitle">R4: CLARIS enables effective communication for people suffering from dysarthria</h3>
        <h4 class="gtText">The following samples are for speakers from TORGO corpus</h4>
        <div class="row d-flex table-responsive overflow-auto audioContainer" id="TORGOContainer"></div>
    </div>
    <script src="scripts.js"></script>
</body>

</html>